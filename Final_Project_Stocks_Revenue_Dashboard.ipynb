{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6151bb4",
   "metadata": {},
   "source": [
    "# Final Project: Stock Price vs Revenue Dashboard (Tesla & GameStop)\n",
    "\n",
    "**Name:** _Your Name Here_\n",
    "\n",
    "**Date:** 2025-09-01\n",
    "\n",
    "---\n",
    "This notebook completes the 7 questions specified in the assignment. It uses **yfinance** to pull stock prices and **web scraping** to collect quarterly revenue from Macrotrends. Finally, it builds dashboards comparing stock price to revenue for **Tesla (TSLA)** and **GameStop (GME)**.\n",
    "\n",
    "> ⚠️ **Before you run this notebook**: Ensure you have completed the previous yfinance and web scraping labs and that your environment has internet access.\n",
    "\n",
    "## What you'll submit\n",
    "- **Screenshots** clearly showing each question header, the code you executed, and the resulting output/plots.\n",
    "- **Shared copy** of this notebook (export to HTML or share via repo) for Question 7.\n",
    "\n",
    "## Grading (12 points total)\n",
    "- Q1 TSLA stock (2), Q2 TSLA revenue (1), Q3 GME stock (2), Q4 GME revenue (1)\n",
    "- Q5 TSLA dashboard (2), Q6 GME dashboard (2), Q7 Share notebook (2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d34961",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Install or import required libraries. If you're in a fresh environment, uncomment the `pip install` lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bf854c2",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.width', 120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad77da2",
   "metadata": {},
   "source": [
    "---\n",
    "## Helper: Clean Revenue Table from Macrotrends\n",
    "Macrotrends pages contain multiple tables; we specifically want the **Quarterly Revenue** table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce72ea17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_quarterly_revenue(macrotrends_url: str) -> pd.DataFrame:\n",
    "    \"\"\"Scrape Quarterly Revenue table (Date, Revenue) from a Macrotrends revenue page.\n",
    "    Example URLs:\n",
    "      Tesla:    https://www.macrotrends.net/stocks/charts/TSLA/tesla/revenue\n",
    "      GameStop: https://www.macrotrends.net/stocks/charts/GME/gamestop/revenue\n",
    "    \"\"\"\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    html = requests.get(macrotrends_url, headers=headers).text\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    tables = soup.find_all(\"table\")\n",
    "\n",
    "    target_table = None\n",
    "    for tbl in tables:\n",
    "        caption = tbl.find_previous_sibling('h2')\n",
    "        if caption and 'Quarterly Revenue' in caption.get_text(strip=True):\n",
    "            target_table = tbl\n",
    "            break\n",
    "\n",
    "    if target_table is None:\n",
    "        # Fallback: pick the first table that has 'Revenue' in header\n",
    "        for tbl in tables:\n",
    "            th = tbl.find('th')\n",
    "            if th and 'Revenue' in th.get_text():\n",
    "                target_table = tbl\n",
    "                break\n",
    "\n",
    "    if target_table is None:\n",
    "        raise ValueError(\"Quarterly Revenue table not found on the page. Structure may have changed.\")\n",
    "\n",
    "    df = pd.read_html(str(target_table))[0]\n",
    "    # Expect columns like ['Date', 'Revenue']\n",
    "    df.columns = [c.strip() for c in df.columns]\n",
    "    # Keep only 'Date' and 'Revenue' if present\n",
    "    keep_cols = [c for c in df.columns if c.lower().startswith('date') or c.lower().startswith('revenue')]\n",
    "    df = df[keep_cols]\n",
    "    # Standardize column names\n",
    "    rename_map = {c: 'Date' if 'date' in c.lower() else ('Revenue' if 'revenue' in c.lower() else c) for c in df.columns}\n",
    "    df = df.rename(columns=rename_map)\n",
    "    # Clean revenue string: remove $ and commas; coerce to numeric\n",
    "    df['Revenue'] = (df['Revenue']\n",
    "                     .astype(str)\n",
    "                     .str.replace('$', '', regex=False)\n",
    "                     .str.replace(',', '', regex=False)\n",
    "                     .str.replace(' ', '', regex=False)\n",
    "                    )\n",
    "    df['Revenue'] = pd.to_numeric(df['Revenue'], errors='coerce')\n",
    "    df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "    df = df.dropna(subset=['Date', 'Revenue']).sort_values('Date').reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69944da3",
   "metadata": {},
   "source": [
    "---\n",
    "## Helper: Stock Downloader via yfinance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f1a1e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_stock_history(ticker: str, start: str = '2010-01-01') -> pd.DataFrame:\n",
    "    \"\"\"Download daily history with yfinance and keep Date, Close columns\"\"\"\n",
    "    data = yf.download(ticker, start=start, progress=False)\n",
    "    data = data[['Close']].dropna().reset_index()\n",
    "    data.columns = ['Date', 'Close']\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2b775d",
   "metadata": {},
   "source": [
    "## Helper: Dashboard (Price vs Revenue)\n",
    "Creates a 2-row interactive Plotly figure: stock price on top, quarterly revenue on bottom.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68f27241",
   "metadata": {},
   "outputs": [],
   "source": [
    "def price_vs_revenue_dashboard(price_df: pd.DataFrame, revenue_df: pd.DataFrame, title: str):\n",
    "    fig = make_subplots(rows=2, cols=1, shared_xaxes=True, vertical_spacing=0.1,\n",
    "                        subplot_titles=(f\"{title} - Closing Price\", f\"{title} - Quarterly Revenue\"))\n",
    "    # Price trace\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=price_df['Date'], y=price_df['Close'], mode='lines', name='Close'),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    # Revenue trace\n",
    "    fig.add_trace(\n",
    "        go.Bar(x=revenue_df['Date'], y=revenue_df['Revenue'], name='Revenue'),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    fig.update_layout(height=700, width=1000, title_text=title, showlegend=True)\n",
    "    fig.update_xaxes(title_text='Date', row=2, col=1)\n",
    "    fig.update_yaxes(title_text='Price (USD)', row=1, col=1)\n",
    "    fig.update_yaxes(title_text='Revenue (USD)', row=2, col=1)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baeae936",
   "metadata": {},
   "source": [
    "---\n",
    "## Question 1 — Extracting Tesla Stock Data Using yfinance (2 pts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66f12d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nihal Shaikh\\AppData\\Local\\Temp\\ipykernel_3480\\3304570534.py:3: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker, start=start, progress=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date     Close\n",
      "0 2010-06-29  1.592667\n",
      "1 2010-06-30  1.588667\n",
      "2 2010-07-01  1.464000\n",
      "3 2010-07-02  1.280000\n",
      "4 2010-07-06  1.074000\n",
      "           Date       Close\n",
      "3812 2025-08-25  346.600006\n",
      "3813 2025-08-26  351.670013\n",
      "3814 2025-08-27  349.600006\n",
      "3815 2025-08-28  345.980011\n",
      "3816 2025-08-29  333.869995\n"
     ]
    }
   ],
   "source": [
    "tsla_price = download_stock_history('TSLA', start='2010-01-01')\n",
    "print(tsla_price.head())\n",
    "print(tsla_price.tail())\n",
    "# Optional: save for reference\n",
    "tsla_price.to_csv('tsla_price.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7c8a6e",
   "metadata": {},
   "source": [
    "## Question 2 — Extracting Tesla Revenue Data Using Web Scraping (1 pt)\n",
    "We use Macrotrends' revenue page for Tesla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fa491c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nihal Shaikh\\AppData\\Local\\Temp\\ipykernel_3480\\1699775314.py:30: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(target_table))[0]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Revenue'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Revenue'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m tsla_rev_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.macrotrends.net/stocks/charts/TSLA/tesla/revenue\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m tsla_revenue \u001b[38;5;241m=\u001b[39m scrape_quarterly_revenue(tsla_rev_url)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(tsla_revenue\u001b[38;5;241m.\u001b[39mhead())\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(tsla_revenue\u001b[38;5;241m.\u001b[39mtail())\n",
      "Cell \u001b[1;32mIn[7], line 40\u001b[0m, in \u001b[0;36mscrape_quarterly_revenue\u001b[1;34m(macrotrends_url)\u001b[0m\n\u001b[0;32m     38\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39mrename_map)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Clean revenue string: remove $ and commas; coerce to numeric\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRevenue\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRevenue\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     41\u001b[0m                  \u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\n\u001b[0;32m     42\u001b[0m                  \u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m$\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     43\u001b[0m                  \u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     44\u001b[0m                  \u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     45\u001b[0m                 )\n\u001b[0;32m     46\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRevenue\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_numeric(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRevenue\u001b[39m\u001b[38;5;124m'\u001b[39m], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     47\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Revenue'"
     ]
    }
   ],
   "source": [
    "tsla_rev_url = \"https://www.macrotrends.net/stocks/charts/TSLA/tesla/revenue\"\n",
    "tsla_revenue = scrape_quarterly_revenue(tsla_rev_url)\n",
    "print(tsla_revenue.head())\n",
    "print(tsla_revenue.tail())\n",
    "tsla_revenue.to_csv('tsla_revenue.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55add961",
   "metadata": {},
   "source": [
    "---\n",
    "## Question 3 — Extracting GameStop Stock Data Using yfinance (2 pts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1787556e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gme_price = download_stock_history('GME', start='2010-01-01')\n",
    "print(gme_price.head())\n",
    "print(gme_price.tail())\n",
    "gme_price.to_csv('gme_price.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58e9cc2",
   "metadata": {},
   "source": [
    "## Question 4 — Extracting GameStop Revenue Data Using Web Scraping (1 pt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd93a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gme_rev_url = \"https://www.macrotrends.net/stocks/charts/GME/gamestop/revenue\"\n",
    "gme_revenue = scrape_quarterly_revenue(gme_rev_url)\n",
    "print(gme_revenue.head())\n",
    "print(gme_revenue.tail())\n",
    "gme_revenue.to_csv('gme_revenue.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1daee8a",
   "metadata": {},
   "source": [
    "---\n",
    "## Question 5 — Tesla Stock and Revenue Dashboard (2 pts)\n",
    "Creates an interactive two-panel dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb49e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_tsla = price_vs_revenue_dashboard(tsla_price, tsla_revenue, title='Tesla (TSLA) — Price vs Quarterly Revenue')\n",
    "fig_tsla.show()\n",
    "# Save a static image if you have kaleido installed:\n",
    "# !pip install -U kaleido\n",
    "# fig_tsla.write_image('tesla_dashboard.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8696ee",
   "metadata": {},
   "source": [
    "## Question 6 — GameStop Stock and Revenue Dashboard (2 pts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d56126e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_gme = price_vs_revenue_dashboard(gme_price, gme_revenue, title='GameStop (GME) — Price vs Quarterly Revenue')\n",
    "fig_gme.show()\n",
    "# Save a static image if you have kaleido installed:\n",
    "# fig_gme.write_image('gamestop_dashboard.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab31a88c",
   "metadata": {},
   "source": [
    "---\n",
    "## Question 7 — Sharing Your Assignment Notebook (2 pts)\n",
    "Export this notebook to **HTML** and share the HTML or upload to a repository.\n",
    "\n",
    "**How to export in Jupyter:**\n",
    "- `File > Save and Checkpoint`\n",
    "- `File > Download as > HTML (.html)`\n",
    "\n",
    "**What to upload for grading:**\n",
    "- Screenshots showing the code **and** outputs for Q1–Q6\n",
    "- The shared notebook file (HTML or notebook link)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171d3b75",
   "metadata": {},
   "source": [
    "---\n",
    "## (Optional) Sanity Checks & Alignment of Frequencies\n",
    "Price is **daily** while revenue is **quarterly**. For plotting they are shown on the same x-axis but different frequencies. If you need to align them explicitly, this helper aggregates price to quarter-end.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99184b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_quarter_end(df_price: pd.DataFrame) -> pd.DataFrame:\n",
    "    q = (df_price\n",
    "         .set_index('Date')['Close']\n",
    "         .resample('Q')\n",
    "         .last()\n",
    "         .reset_index())\n",
    "    q.columns = ['Date', 'Close']\n",
    "    return q\n",
    "\n",
    "# Example usage (optional):\n",
    "# tsla_price_q = to_quarter_end(tsla_price)\n",
    "# gme_price_q  = to_quarter_end(gme_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09def62c",
   "metadata": {},
   "source": [
    "---\n",
    "## (Optional) Save Clean Datasets\n",
    "This saves tidy CSVs you can reuse or turn in alongside screenshots.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5165a436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Already saved above; you can re-run anytime:\n",
    "# tsla_price.to_csv('tsla_price.csv', index=False)\n",
    "# tsla_revenue.to_csv('tsla_revenue.csv', index=False)\n",
    "# gme_price.to_csv('gme_price.csv', index=False)\n",
    "# gme_revenue.to_csv('gme_revenue.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb254b3",
   "metadata": {},
   "source": [
    "---\n",
    "## (Optional) Peer Review Checklist (for grading a peer)\n",
    "- [ ] **Q1:** yfinance used for TSLA; dataframe printed; looks correct\n",
    "- [ ] **Q2:** Web scraping used for TSLA revenue; columns cleaned to numeric; dates parsed\n",
    "- [ ] **Q3:** yfinance used for GME; dataframe printed; looks correct\n",
    "- [ ] **Q4:** Web scraping used for GME revenue; columns cleaned to numeric; dates parsed\n",
    "- [ ] **Q5:** Dashboard shows TSLA price (line) and revenue (bar) with appropriate labels\n",
    "- [ ] **Q6:** Dashboard shows GME price (line) and revenue (bar) with appropriate labels\n",
    "- [ ] **Q7:** Notebook shared (HTML or link); screenshots clearly show code **and** outputs\n",
    "- [ ] Code quality: clear functions, comments, no hard-coded fragile selectors\n",
    "- [ ] Data quality: no obvious NaNs in key columns; sorted by Date\n",
    "- [ ] Visual quality: axes labeled, titles present\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59024a95-991f-4e94-8451-504191fb119b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install yfinance requests bs4 plotly pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a08938-a6ce-407a-93bb-5d05cda62dc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b62588e-fbd3-4818-91cb-8d056d446173",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2875debe-6b89-4709-94b9-393b392044ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c974653e-c707-4228-95d6-e337abb8614c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
